### Introduction to Quantitative and Qualitative Research Design

By now you should be familiar with the terms quantitative research and qualitative research.  Plano-Clark and Creswell \(2010\) assert that these research approaches are suited to different kinds of research questions:  a quantitative research approach is indicated when the research problem requires _**an explanation**_, while a qualitative research approach is indicated when the research problem requires _**exploration**_ \(pp. 85-86\).  Expanding on that somewhat, Leedy and Ormrod assert that quantitative research has three purposes:  to explain and predict, to confirm and validate, and to test theory.  In contrast, qualitative research has three distinct purposes:  to describe and explain, to explore and interpret, and to build theory \(Leedy & Ormrod, 2010, p. 96\).  These differing research purposes find expression in differing research processes, the kinds of data gathered, the approaches to data analysis, and finally in the ways findings are communicated.

In this unit we will be looking at the methods and results sections of _quantitative research reports,_ and in unit 6 we will do the same for qualitative research reports.  We will see that a variety of different research designs under both of these general approaches.  For example, Gill and Johnson \(2002\) have developed a helpful continuum \(depicted in the figure below\) that describes the relative emphasis of various research designs on selected characteristics.  They argue that quantitative designs \(including survey research\) tend towards deduction while qualitative designs are inductive in nature.

![](/assets/researchmethods.jpg)According to Leedy and Ormrod, the nature of quantitative and qualitative research designs differ \(2010, p. 96\).  Quantitative designs tend to be more closely focused on a problem that has known variables that can be controlled or at least accounted for.  The investigation is conducted following established guidelines utilizing largely predetermined methods while the researcher seeks to maintain a detached view.  In contrast, qualitative designs tend to be more holistic, investigating unknown variables following flexible guidelines utilizing emergent methods in a highly context-bound, personal approach.  Qualitative designs may be characterized as evolving and flexible, sometimes guided by a general hunch as to how to proceed \(Bogdan & Biklen, 2007, p. 45\).

These differing designs lead to marked differences in what data are collected, how data are collected, and how data are analyzed.  Quantitative research seeks to collect numeric data from as large a sample as possible so to enhance claims to being representative, using standardized data collection instruments.  Qualitative research gathers textual or image-based data from typically small, informative samples using loosely structured or nonstandardized interviews or observations \(Leedy & Ormrod, 2010, p. 96\).

The differing designs of quantitative and qualitative research also lead marked differences in how data is analyzed.  Quantitative data is approached primarily through deductive reasoning, employing statistical analyses applied to numerical data, with stress on objectivity.  Qualitative data is approached primarily through inductive reasoning with the goal uncovering themes and categories, with acknowledgement of potential researcher bias and subjectivity.  Typically, quantitative research findings are reported in a formal, scientific style with full display of numbers and statistics, while qualitative research findings are typically reported in a narrative form \(Leedy & Ormrod, 2010, p. 96\).  In the following sections, we will unpack this somewhat for quantitative research.

### Quantitative Research Designs

Quantitative research designs typically rely on the researcher beginning with a theoretical framework, that will determine what concepts the researcher chooses to investigate, the suggestion of research questions, and the framing of research findings \(Corbin & Strauss, 2008, p. 39\).  These frameworks lead to a structured, predetermined, formal, and specifically detailed plan of operation \(Bogdan & Biklen, 2007, p. 45\).

In Chapter 6, Plano-Clark and Creswell \(2015\) discuss five quantitative research designs: true experiments, quasi-experiment, single-subject, correlational and survey research designs.  Take note of where three of these are situated in Gill and Johnson’s continuum above. The extreme left of the continuum is held by experiments.  Experiments—particularly randomized control trials \(RCTs\)—are often held up as the “gold standard” of research, meeting the criteria of randomization, control, and manipulation of variables \(i.e., experimental procedures, treatments, or interventions\).   In the domain of knowledge transfer and evidence-based practice, RCTs are considered as the highest level or most reliable form of evidence.

By way of caution, Gill and Johnson \(2002\) observe that except as it borders the disciplinary areas of psychology and information systems, management and leadership research seldom employs classical experimentation. They posit that this is because true experiments are difficult to conduct in natural everyday settings, due to the difficulty of maintaining the tight controls required for experimental research. Having said this, there is relevance for us because the logic underpinning experimental research applies to other types of deductive research that are more common in management and leadership research.  When not all of the rigorous standards required of experiments can be applied to a study, researchers approximate some of the logic of the experiment with quasi-experimental designs.

Quasi-experimental designs resemble experimental designs in that they include manipulation of an independent variable but differ in that they lack either a control group or random assignment.  Ex-post facto designs do not involve experimentation \(i.e, manipulation of the independent variable\) but observe the effects of manipulating the independent variable after it has occurred.

Gall, Gall and Borg \(2007\) recognize two main categories of quantitative research design: non-experimental and experimental.  In true experimental and quasi-experimental designs, the researcher intentionally introduces an intervention, and then seeks to measure the response to that intervention.  The main difference between experimental and quasi-experimental designs lies in the way sampling is done.  In non-experimental quantitative research designs, the researcher seeks to understand the behavior or attributes of the study sample without any researcher intervention.  The terms descriptive, causal-comparative and correlational are often applied to these types of quantitative research designs.

As a consumer of research reports, you can usually find in the abstract an indication of what research methodology is employed by the study.  This is important information for you to identify, as you will quickly develop a sense of what to expect as you continue to read.  This sense is important as you critique the research report, and make value judgments as to it’s worth.

Method Section:  Quantitative Data Collection

The research problem establishes why a particular research study is worth doing, the review of precedent literature establishes what is already known about the problem, the research purpose establishes what the research specifically intends to do, and the research design provides the overall plan for the research study.  We now turn our attention to quantitative research data collection.

Quantitative research data is obviously numeric, and may consist of quantifiable coding, counts and measures, operationalized variables, and statistics.  Quantitative data is collected from large, stratified samples, employing control groups, selected ideally through random selection.  A great deal of attention is typically directed to the control of extraneous variables \(Bogdan & Biklen, 2007, p. 45\).

Chapter 7 of Plano-Clark and Creswell \(2015\) explores how data is collected in quantitative research studies.  In this they assert that two considerations are primary:  who is the researcher collecting data from, and how are they collecting it?  In answering the first question, the terms population and sample are salient.  Population is the large category that encompasses all of the individuals who possess or exhibit certain characteristics of interest to the study.  Sample refers to the individuals from the population that you actually gather data from.  The goal in sampling is to find a representative sample that accurately represents that population.

In defining the population, Gall, Gall and Borg \(2007\) differentiate between target and accessible populations \(p. 166\).  The target population is what statisticians often refer to as the universe.  Once the target population is defined, for practical reasons a representative sample is sought.  The accessible population is those individuals who could realistically be included in the sample.

In quantitative research, a primary interest is in generalizability: To what degree can the results be generalized back to the general population?  This generalization requires an inferential leap from the sample back to the population.  Population validity is a term that is applied to this, and is a valuable criterion in judging a research report.  In quantitative research, samples are drawn from the accessible population through processes of probability sampling and nonprobability sampling.  One of the major differences between quantitative and qualitative research lies in these two terms:  qualitative research rests almost invariably on nonprobability sampling.  This will be explored more deeply in Day 6.

A number of probability sampling techniques to enhance population validity are discussed by Plano-Clark and Creswell \(2015\) in Chapter 7.  The gold standard is true random sample of the accessible population.  Random sampling techniques can become very elaborate.  Gall, Gall and Borg discuss simple random sampling, systematic random sampling, stratified random sampling—including proportional and non proportional variants, and cluster sampling—including simple and multistage variants \(2007, pp.170-174\).   A common nonprobability sampling technique commonly employed in quantitative research is convenience sampling.  As you would infer from the term, the sample is selected from the accessible population that is most convenient.

Another important consideration is sample size.  Sample size will have direct impact on population validity.  For that reason, qualitative researchers usually seek to use the largest sample possible.  Well established rules of thumb have been widely accepted regarding minimum sample numbers:  for example, correlational research typically seeks a minimum sample of 30; causal-comparative and experimental research should have at least 15 in each group to be compared; survey research at least 100 in each group, and 20 to 50 in each subgroup \(Gall, Gall & Borg, 2007, p. 176\).

The second major consideration in qualitative data collection is how the data is collected.  In quantitative research tests are often employed.  Quantitative research data collection instruments and tools may include inventories, questionnaires, indexes, scales and test scores \(Bogdan & Biklen, 2007, p. 46\).  As a consumer of research, when judging the quality of tests used in research consider the criteria of objectivity, standardization of conditions of administration, scoring and interpretation, and finally, fairness \(Gall, Gall & Borg, 2007, pp. 194-195\).  Issues of test validity and test reliability \(measurement error\) must also be considered.  Numerous tests have been developed to measure performance, including intelligence tests, aptitude tests, achievement tests, diagnostic tests, and performance assessment tests.  Gall, Gall and Borg suggest that criteria for judging the validity of performance assessment tests should include consideration of consequences, fairness, generalizability, cognitive complexity, content quality, meaningfulness, content coverage and cost and efficiency \(2007, p. 217\).

Numerous tests also exist that measure personal characteristics.  Included are personality inventories, measures of personality traits, self-concept, learning styles and habits, attitude scales and measures of vocational interest.   The consumer of quantitative research reports is well advised to consider the following questions regarding tests that purport to measure personal characteristics:  
1.     What evidence exists that the test is valid and reliable for the uses it is put to?  
2.    Is the test’s reading or task level appropriate to the sample?  
3.    Do the test’s norms and evidence of validity and reliability come from a population similar to the study population?  \(Adapted from Gall, Gall & Borg, 2007, p. 220\)

Quantitative research data may also be collected through various self-reporting methods, through researcher observation and through content analysis.  Well-developed norms for each of these approaches have developed and are accessible in detail in standard research texts such as Gall, Gall and Borg \(2010\).

Survey Research

At this point we want to focus on survey research for a few moments because of its wide use in leadership and management settings.  While the survey is a method of data collection that may be used in qualitative research \(Gall, Gall & Borg, 2007, p. 227\), it is extensively employed in quantitative research \(Plano-Clark & Creswell, 2015, p. 207\).  Be aware of ambiguities in how the term survey is used \(see Here’s a Tip! on page 207\).  Often the term is used as a general label to denote the use of questionnaires or interviews in research.  Because of the differences in intentions for generalizability between quantitative and qualitative research, this ambiguity is not helpful.  Plano-Clark and Creswell see survey research as a form of quantitative research, sitting near the end of that continuum \(2015, p. 197\).  For others, including Gall, Gall and Borg \(2007\), the term survey research does not refer to a particular type of research design, but rather to a process of collecting data to achieve the purposes of other research designs.  They assert that survey research is particularly applicable to serving the interests of descriptive, causal-comparative and case-study research designs \(Gall, Gall & Borg, 2007, p. 230\).

Survey research is a popular research method used to generalize from a sample to a population in order that inferences can be made about some characteristic, attitude, or behavior of the larger population \(Creswell, 2003\).  Survey research may be conducted through use of either questionnaires or interviews.  These methods allow the researcher to collect data about observable phenomena as well as phenomena that would be difficult to otherwise assess \(i.e., opinions, values, feelings, etc.\).   Questionnaires present the same questions in some form of print to all study participants uniformly, and responses are received in like manner.  In interviews, the researcher presents the same questions orally to study participants, usually one at a time, but increasingly in groups, and the responses are received orally. The main difference in the two approaches lies in the fact that with questionnaires the research participant is largely in control of the response situation, whereas in the interview the researcher is largely in control.  Each approach has relative advantages and disadvantages, but share in common the desire to collect data in standardized ways.  For this reason, closed ended questions are typically used, and in questionnaires, often with forced responses \(i.e. select a number on a Likert scale\).

As a consumer of survey research reports, be vigilant for potential issues of validity and reliability.   Validity refers to the “appropriateness, meaningfulness, and usefulness of specific inferences” \(Gall, Gall & Borg, 2007, p. 657\).  In other words, validity is a term that forces us to question the likelihood of whether this instrument or study actually measures what the researcher says it does.  Plano-Clark and Creswell provide a cogent discussion of issues of internal and external validity \(2010, pp. 193-194.\)  Reliability issues concern the consistency or repeatability of the instrument.  Be aware that survey research is commonly criticized on these grounds, a fact underscored in Plano-Clark and Creswell’s suggestion to remedy possible concerns for internal validity by choosing a quantitative research design other than survey \(Plano-Clark & Creswell, 2010, p. 193\).

Results Section:  Quantitative Data Analysis and Results

Quantitative research data analysis is generally deductive, occurs at the conclusion of data collection, and is statistical \(Bogdan and Biklen, 2007, p. 46\).  An in-depth understanding or even an overview of statistical analysis is outside the parameters of this course.  However, even if you do not have a background in statistics, you must find your way through what can initially appear to be a daunting discussion.

The methods section of a quantitative research report typically presents a brief description of various statistical manipulations employed in the course of the analysis of data.  The statistical manipulation chosen depends on the kind of questions asked in the research.  Descriptive statistics are applied to descriptive questions.  Descriptive statistics include various measures of central tendency \(including mean, median, mode, skewness, and categorical data such as frequency distribution\), measures of variability \(including standard deviation,  the normal curve, variance and range\), and correlational statistics \(including bivariate and multivariate correlational methods\).  Table 8.1 on page 214 of Plano-Clark and Creswell is a useful summary of descriptive statistics terminology.

Inferential statistics are applied to data in an effort to answer comparison and relationship sorts of questions.  The initial step is to establish the null hypothesis \(that is, to posit that the intervention will have no effect\) and then apply a test of statistical significance to determine if the null hypothesis can be rejected \(Gall, Gall & Borg, 2007, p. 138\).  A Type I error is the unwarranted rejection of the null hypothesis, while a Type II error is the unwarranted acceptance of the null hypothesis.  These two errors are interrelated:  seeking a high level of significance reduces the likelihood of a Type I error but simultaneously raises the likelihood of a Type II error.  The discussion found regarding the alpha level on page 218 of Plano-Clark and Creswell \(2010\) is specifically referencing this.  An alpha of .05 means that the researchers want to have no more than a 5% chance of saying there is a difference, while there really isn’t.

Tests of statistical significance are designed to work when samples are drawn randomly.  Be aware that true random sampling is rare in most quantitative research studies.  Gall, Gall and Borg suggest that statistical significance tests “should be used with caution, or not at all, under conditions of nonrandom sampling, nonrandom assignment, or low statistical power” \(2007, p. 142\).  Statistical power is the probability that the particular statistical significance test will in fact reject a false null hypothesis.  Statistical power rests on consideration of sample size, level of significance chosen, whether directionality is specified in the research hypothesis, and effect size \(Gall, Gall & Borg, 2007, p. 143\).

A useful chart showing some common inferential statistics are found in Tables 8.2 and 8.3 on pages 219 and 220 of Plano-Clark and Creswell.  As a consumer of qualitative research reports, you will want to satisfy yourself that the statistics employed are appropriate, and to be cautious about accepting research findings if you detect any inconsistencies.

References:

Bogdan, R. &  Biklen, S. \(2007\).  Qualitative research for education: An introduction to theories and method \(5th ed.\).  Boston:  Pearson.

Corbin, J. & Strauss, A. \(2008\).  Basics of qualitative research \(3rd ed\).  Los Angles, CA:  Sage.

Creswell, J. \(2003\).  Research design: Qualitative, quantitative, and mixed methods approaches \(2nd ed.\).  Thousand Oaks, CA:  Sage.

Gall, M., Gall, J. & Borg, W.  \(2007\). Educational research.  Boston, MA:  Pearson.

Gill, J., & Johnson, P. \(2002\).  Research methods for managers \(3rd ed.\).  Chapter 6.  Survey research design \(pp. 97-122\).  Thousand Oaks, CA:  Sage

Leedy, P., & Ormrod, J. \(2010\). Practical research: Planning and design \(9th ed.\). Upper Saddle River, NJ: Prentice-Hall.

Plano-Clark, V. & Creswell, J. \(2010\). Understanding research: A consumer’s guide. Boston, MA: Merrill.

Plano-Clark, V., Creswell, J. \(2015\). Understanding research: A consumer’s guide \(2nd ed.\). Boston, MA: Pearson

